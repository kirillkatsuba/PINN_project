{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1848d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2094b82",
   "metadata": {},
   "source": [
    "The thermal conductivity equation:\n",
    "$\\frac{\\partial T}{\\partial t} - \\frac{{\\partial}^2 T}{\\partial x^2} = 0$\n",
    "\n",
    "Assume $ T(t, x) = 2 + e^{-4 \\pi^2 t} sin(2\\pi x) + e^{-16\\pi^2 t} cos(4\\pi x)$, $x\\in[0,1], t\\in[0, 0.05]$\n",
    "$\\\\$Boundary condition $T_0 = T(0, x) = 2 + sin(2\\pi x) + cos(4\\pi x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a86c6621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define amount of sample points\n",
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f284f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the beginning we plot graph of the thermal conductivity process\n",
    "def f_real(t, x):\n",
    "    return (2 + torch.exp(-4*(torch.pi**2)*t)*torch.sin(2*torch.pi*x) + torch.exp(-16*(torch.pi**2)*t)*torch.cos(4*torch.pi*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1569e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to get test points from equation in first cell\n",
    "x_data = torch.rand(N).view(-1,1)\n",
    "t_data = 0.01 * torch.rand(N).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba50661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the class PINN\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self,input_layer=2,h1=64,h2=64,h3=64,output_layer=1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_layer,h1)\n",
    "        self.fc2 = nn.Linear(h1,h2)\n",
    "        self.fc3 = nn.Linear(h2,h3)\n",
    "        self.fc4 = nn.Linear(h3,output_layer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.gelu(self.fc1(x))\n",
    "        x = F.gelu(self.fc2(x))\n",
    "        x = F.gelu(self.fc3(x))\n",
    "        x = F.gelu(self.fc4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc5f4e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x112e1d550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_phys = torch.rand(N).view(-1,1).requires_grad_(True)\n",
    "t_ = 5 * torch.rand(N).view(-1,1)\n",
    "t_phys = t_.requires_grad_(True)\n",
    "points = torch.stack((t_phys,x_phys), -1)\n",
    "points_bc = torch.stack((torch.zeros(N,1), x_phys), -1)\n",
    "torch.manual_seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "066fcf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn = PINN()\n",
    "optimizer = torch.optim.Adam(pinn.parameters(), lr=0.01)#SGD, \n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 60, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee037300",
   "metadata": {},
   "source": [
    "Loss1 = $\\frac{1}{N} \\sum_{i=1}^{N}(T(t_i, x_i)- f_{PINN}(t_i, x_i))^2$\n",
    "\n",
    "Loss2 = $\\frac{1}{N} \\sum_{i=1}^{N}(T_0(x_i)- f_{PINN}(0, x_i))^2$\n",
    "\n",
    "Loss3 = $\\frac{1}{N} \\sum_{i=1}^{N}(\\frac{\\partial}{\\partial t}f_{PINN}(t_i, x_i) - \\frac{{\\partial}^2 }{\\partial x^2}f_{PINN}(t_i, x_i))^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f79331c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\tamount of loss: 9.264941215515137\t\n",
      "epoch: 50\tamount of loss: 4.5181379318237305\t\n",
      "epoch: 100\tamount of loss: 2.562826156616211\t\n",
      "epoch: 150\tamount of loss: 1.5607805252075195\t\n",
      "epoch: 200\tamount of loss: 1.6356854438781738\t\n",
      "epoch: 250\tamount of loss: 1.5877504348754883\t\n",
      "epoch: 300\tamount of loss: 1.5806422233581543\t\n",
      "epoch: 350\tamount of loss: 1.5771487951278687\t\n",
      "epoch: 400\tamount of loss: 1.575698971748352\t\n",
      "epoch: 450\tamount of loss: 1.5751796960830688\t\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Neural network training using sum of MSE, boundary condition and partial dirivatives.\n",
    "\"\"\"\n",
    "epochs = 500\n",
    "\n",
    "for i in range(epochs):\n",
    "    #compute MSE of T(t,x) and points that were pridicted by PINN\n",
    "    network = pinn.forward(points)\n",
    "    loss1 = torch.mean((f_real(t_data, x_data) - network)**2)\n",
    "    y_bc = pinn.forward(points_bc)\n",
    "    loss2 = torch.mean((f_real(torch.zeros_like(x_data), x_data) - y_bc)**2)\n",
    "    \n",
    "    #compute loss using derivatives\n",
    "    dt = torch.autograd.grad(network, t_phys, torch.ones_like(network), create_graph=True)[0]\n",
    "    dx = torch.autograd.grad(network, x_phys, torch.ones_like(network), create_graph=True)[0]\n",
    "    dx2 = torch.autograd.grad(dx, x_phys, torch.ones_like(dx), create_graph=True)[0]\n",
    "    loss3 = torch.mean((dt - dx)**2)\n",
    "    \n",
    "    loss = loss1 + loss2 + loss3\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    scheduler.step(loss)\n",
    "    if i % 50 == 0:\n",
    "        print(f'epoch: {i}\\tamount of loss: {loss}\\t')#learning rate: {scheduler.get_last_lr()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b2a2781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0844, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#MSE between neural network and given function\n",
    "f_nn = pinn.forward(points)\n",
    "print(torch.mean((f_real(t_data, x_data) - f_nn)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6852917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\tamount of loss: 4.951014041900635\t\n",
      "epoch: 50\tamount of loss: 1.277353286743164\t\n",
      "epoch: 100\tamount of loss: 1.3161898851394653\t\n",
      "epoch: 150\tamount of loss: 1.2619175910949707\t\n",
      "epoch: 200\tamount of loss: 1.1619625091552734\t\n",
      "epoch: 250\tamount of loss: 1.1108143329620361\t\n",
      "epoch: 300\tamount of loss: 1.0971288681030273\t\n",
      "epoch: 350\tamount of loss: 1.093517541885376\t\n",
      "epoch: 400\tamount of loss: 1.0925331115722656\t\n",
      "epoch: 450\tamount of loss: 1.0922656059265137\t\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Neural network training using only partial dirivatives and boundary condition.\n",
    "\"\"\"\n",
    "pinn_new = PINN()\n",
    "optimizer_new = torch.optim.Adam(pinn_new.parameters(), lr=0.01)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 60, gamma=0.5)\n",
    "scheduler_new = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_new, 'min', factor=0.75)\n",
    "epochs = 500\n",
    "\n",
    "for i in range(epochs):\n",
    "    #compute MSE of T(t,x) and points that were pridicted by PINN\n",
    "    network_new = pinn_new.forward(points)\n",
    "    y_bc_new = pinn_new.forward(points_bc)\n",
    "    loss2_new = torch.mean((f_real(torch.zeros_like(x_data), x_data) - y_bc_new)**2)\n",
    "    \n",
    "    #compute loss using derivatives\n",
    "    dt_new = torch.autograd.grad(network_new, t_phys, torch.ones_like(network_new), create_graph=True)[0]\n",
    "    dx_new = torch.autograd.grad(network_new, x_phys, torch.ones_like(network_new), create_graph=True)[0]\n",
    "    dx2_new = torch.autograd.grad(dx_new, x_phys, torch.ones_like(dx_new), create_graph=True)[0]\n",
    "    loss3_new = torch.mean((dt_new - dx_new)**2)\n",
    "    \n",
    "    loss_new = loss2_new + loss3_new\n",
    "    loss_new.backward()\n",
    "    \n",
    "    optimizer_new.step()\n",
    "    scheduler_new.step(loss)\n",
    "    if i % 50 == 0:\n",
    "        print(f'epoch: {i}\\tamount of loss: {loss_new}\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c575820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0958, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#MSE between neural network and given function\n",
    "f_nn = pinn_new.forward(points)\n",
    "print(torch.mean((f_real(t_data, x_data) - f_nn)**2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
